## Part-A

要从头实现一个 cache-sim，我们先把整体架构想好。

第一部分，我们要解析命令行参数，把对应的结果赋值到全局变量里。

第二部分，我们要解析 trace 文件，得到对应的操作。

第三部分，我们发现 `L/S` 对我们而言完全没区别，都是访问某个 addr 一次；`M` 只是访问某个 addr 两次。所以我们只需要实现一个 `access` 函数就可以了。

接下来只需要仔细地实现每一部分，最后就可以得到完整程序了。

## Part-B

我们采用的 cache 参数是 `s=5,E=1,b=5`，所以这是一个很烂的、direct-mapped cache。

一共有 32 个 line，每个 line 里可以存 8 个 int。缓存一共能放 256 个 int。

### 32*32

由于缓存大小有限，我们考虑之后选择把数组切成 $8\times8$ 的小方块逐块处理。这样如果你访问一个小方块的第一列的话，恰好整个小方块都会被放到缓存里，并且 $64\times2=128$ 是不超过缓存大小的。

观察到，我们 A 和 B 数组的地址非常巧，正好同一位置的高位是对齐的。这意味着对角块的访问会彼此 evict。所以我们处理的重点在于对角块。

对于非对角块的部分，我们只需要依次处理就好了，这会导致 $(16-4)\times8\times2=192$ misses。

对于对角块部分，有一个基本的想法是采用类似于递归的过程实现。然而，递归下去之后的结果不再具有“恰好”的性质，换句话说，这里产生了浪费，最终得到的算法是我们无法接受的。

接下来剩下的 4 个对角块是独立的，我们只需要每个对角块造成的 miss 不超过 51 次即可。

我们把 $8\times8$ 进一步细分为 $4\times4$，然后把 A 的上半部分、B 的下半部分放入 cache，此时我们可以直接把 A 右上块放到 B 左下中。这里其实就是我之前说的类似递归的思路，会造成 $8$ 次 miss。

注意到，我们可以声明 12 个临时变量，尝试利用这一点。

我们贪一手，这里直接把 A 左上块的 12 个值存到临时变量里。

然后 AB 缓存区域互换，把 A 左下放到 B 右上。然后顺便把这 12 个值卸下去。这又是 $8$ misses。

这里有一个小细节，文字不太好描述，但总之，通过合理调整我们访问的顺序，我们可以在不引入额外 miss 的前提下，把 16 个值全都搞进去。

所以最后一个 $8\times8$ 块可以在 $16$ misses 内搞定。

按理说，最终结果应该是 $256$，但是实测结果是 $276$。不过这也正常，因为中间会有访问其他地址。

### 64*64

照着上面的，扩大一下规模就可以了。

草了，怎么跟预期差距这么大？？

好像是因为函数调用一类的访问了一些没啥意义的内存。但也不应该差这么多啊？

全都 inline，循环全都完全展开，还是没救。

我看了一眼 asm，感觉上跟我想写的应该差不多。

所以为啥呢？？摆了。